{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcv-fin0T2Tz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os \n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import glob\n",
        "from collections import defaultdict\n",
        "import shutil\n",
        "import skimage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAyZCi1pmx9W",
        "colab_type": "text"
      },
      "source": [
        "# Download Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVZvM_8_m0Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data_path\n",
        "data_path = '/content/data_path'\n",
        "!wget 'https://kelvins.esa.int/media/competitions/proba-v-super-resolution/probav_data.zip' --no-check-certificate -P data_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b34t9kNm3AF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/data_path/probav_data.zip' -d data_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1VUvD0YnSpx",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing NIR & RED channel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jzIw3xIp9rT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir ='/content/data_path'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOvZlU-tnUjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load images as np.array uint16\n",
        "def load_image( infilename ) :\n",
        "    img = Image.open( infilename )\n",
        "    img.load()\n",
        "    data = np.asarray( img, dtype=\"uint16\" )\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYe_4mseo5xi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalization\n",
        "def normalize(image):\n",
        "    return (image - image.min()) / (image.max() - image.min())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAGbhwPwo_Ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load HR images uint16, Shift them by two to get 14bits values,then convert to float64 \n",
        "def load_and_normalize_hr(scene_path, normalize=False):\n",
        "    hr = skimage.io.imread(scene_path + '/HR.png')\n",
        "    hr = skimage.img_as_float64(hr << 2)\n",
        "    hr = skimage.color.gray2rgb(hr, alpha=None)\n",
        "    hr = hr.reshape(hr.shape[0],hr.shape[1],3)\n",
        "    if normalize:\n",
        "        return normalize(hr)\n",
        "    else:\n",
        "        return hr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFNGV-5bnsX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(band,mode):\n",
        "  # To Compute the PSNR\n",
        "  # norm baseline for each imageset to normalize cPSNR\n",
        "\n",
        "  df_norm=pd.read_csv(os.path.join(base_dir, 'norm.csv'),sep=' ',header=None)\n",
        "  df_norm.columns=['set','norm']\n",
        "  scenes_dir = os.path.join(base_dir, '{}/{}'.format(mode,band))\n",
        "  dir_list=sorted([os.path.basename(x) for x in glob.glob(scenes_dir+'/imgset*')])\n",
        "  norm=df_norm.loc[df_norm['set'].isin(dir_list)]['norm'].values\n",
        "  norm=norm.reshape([norm.shape[0],1])\n",
        "\n",
        "  ##  Parse Dataset and check for any high pixels\n",
        "  ##  and remove the correspond image\n",
        "  ##  Tests conducted on both 60k and 65k and the results was\n",
        "  ##  the same\n",
        "  images_to_remove = []\n",
        "\n",
        "  for i,rep in enumerate(dir_list):\n",
        "      images = sorted(glob.glob(scenes_dir+'/'+rep+'/LR*'))\n",
        "      for j,image in enumerate(images):\n",
        "          image_array = load_image(image)\n",
        "          if (image_array>60000).any() :\n",
        "              images_to_remove.append([i,j])\n",
        "              \n",
        "  img_dico =defaultdict(list)\n",
        "  for i in images_to_remove:\n",
        "      img_dico[i[0]].append(i[1])\n",
        "\n",
        "  ##  Remove the images and the corresponding masks using img_dico \n",
        "  ##  Tests conducted on both 60k and 65k and the results was\n",
        "  ##  the same\n",
        "\n",
        "  for i,rep in enumerate(dir_list):\n",
        "      masks = sorted(glob.glob(scenes_dir+'/'+rep+'/QM*'))\n",
        "      images = sorted(glob.glob(scenes_dir+'/'+rep+'/LR*'))\n",
        "      for rm in img_dico[i]:\n",
        "          os.remove(masks[rm])\n",
        "          os.remove(images[rm])\n",
        "\n",
        "  imgset_selected = []\n",
        "  for rep in dir_list:\n",
        "      images = sorted(glob.glob(scenes_dir+'/'+rep+'/LR*.png'))\n",
        "      masks = sorted(glob.glob(scenes_dir+'/'+rep+'/QM*.png'))\n",
        "      #Combining both LR_images with QM_masks\n",
        "      for image, mask in zip(images,masks):\n",
        "        masked_images = [(skimage.io.imread(image), skimage.io.imread(mask))]\n",
        "        patches_images = []\n",
        "        patches_masks =  []\n",
        "      for image, mask in masked_images:\n",
        "          #Split the images in horizontal and vertical patches\n",
        "          row_patches_images = [np.hsplit(arr,8) for arr in np.vsplit(image,8)]\n",
        "          \n",
        "          row_patches_masks = [np.hsplit(arr,8) for arr in np.vsplit(mask,8)]\n",
        "          \n",
        "          patches_images.append([row_patches_images[i][j] for i in range(len(row_patches_images)) for j in range(len(row_patches_images[i]))])\n",
        "          \n",
        "          patches_masks.append([row_patches_masks[i][j] for i in range(len(row_patches_masks)) for j in range(len(row_patches_masks[i]))])\n",
        "      #Check for patch_mask scores\n",
        "      mask_score = [[np.sum(patch_mask) for patch_mask in mask] for mask in patches_masks]\n",
        "    \n",
        "      combo_patches = [[score[i] for score in mask_score] for i in range(len(mask_score[0]))]\n",
        "      #Find the best patch_mask scores\n",
        "      best_patches = [sorted(range(len(patch)), key = lambda t: patch[t], reverse=True)[0] for patch in combo_patches]\n",
        "      #Get the respective index of patch_mask on patch_image\n",
        "      img_selected = [patches_images[i][j] for j,i in enumerate(best_patches)]\n",
        "      \n",
        "      # Reconstruct the image from patches and apply median filter on it\n",
        "      row_patches = [img_selected[i:i+8] for i in np.arange(0,64,8)]\n",
        "      row_patches = [np.hstack(row_patches[i]) for i in range(len(row_patches))]\n",
        "      constructed_img = np.vstack(row_patches)\n",
        "      constructed_img = skimage.img_as_float64(constructed_img<<2)\n",
        "      constructed_img = skimage.color.gray2rgb(constructed_img, alpha=None)\n",
        "      constructed_img = constructed_img.reshape(constructed_img.shape[0],constructed_img.shape[1],3)\n",
        "      imgset_selected.append(constructed_img)\n",
        "  imgset_arr = np.array(imgset_selected)\n",
        "  np.save(data_path+'/{}_LR_{}.npy'.format(band,mode), imgset_arr)\n",
        "  #Loading HR and preprocessing it\n",
        "  if mode == 'train':\n",
        "    hr_imgs = []\n",
        "    for rep in dir_list:\n",
        "      hr = load_and_normalize_hr(scenes_dir+'/'+rep)\n",
        "      hr_imgs.append(hr)\n",
        "    hrs_arr= np.array(hr_imgs)\n",
        "    np.save(data_path+'/{}_HR_{}.npy'.format(band,mode), imgset_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0JdCN2tup6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_bands(resolution,mode):\n",
        "  nir = np.load('/content/data_path/NIR_{}_{}.npy'.format(resolution,mode))\n",
        "  red = np.load('/content/data_path/RED_{}_{}.npy'.format(resolution,mode))\n",
        "  nired = np.vstack([nir,red])\n",
        "  np.save(data_path+'/{}_{}.npy'.format(resolution,mode), nired)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A488vFXAw1Tc",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing on Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANb-aQryw7W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing('NIR','train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs--zJU9w_zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing('RED','train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVeeQFSTysV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combine_bands('LR','train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1513Ysbby2p8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combine_bands('HR','train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fAKWG7HynxR",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing on Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmbx_UcrzBHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing('NIR','test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AworOeMXzEv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing('RED','test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E3s7koPzgv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combine_bands('LR','test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kl2KdD_zk61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}